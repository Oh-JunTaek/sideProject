import torch
import numpy as np
import cv2
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from resnet_pose_net import ResNetPoseNet  # ëª¨ë¸ íŒŒì¼ import

# COCO Keypoint ì—°ê²° ì •ë³´
COCO_SKELETON = [
    (0, 1), (0, 2), (1, 3), (2, 4),  # ì–¼êµ´ (ì½”-ëˆˆ, ëˆˆ-ê·€ ì—°ê²°)
    (5, 6), (5, 7), (6, 8), (7, 9), (8, 10),  # ìƒì²´ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª© ì—°ê²°)
    (5, 11), (6, 12), (11, 12),  # ëª¸í†µ (ì–´ê¹¨-ê³¨ë°˜ ì—°ê²°)
    (11, 13), (12, 14), (13, 15), (14, 16)  # ë‹¤ë¦¬ (ê³¨ë°˜-ë¬´ë¦-ë°œëª© ì—°ê²°)
]

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = ResNetPoseNet(num_keypoints=17).to(device)
model.load_state_dict(torch.load("pose_model_22.pth", map_location=device))  # ìµœì‹  ëª¨ë¸ ë¡œë“œ
model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_path, target_size=(224, 224)):
    transform = transforms.Compose([
        transforms.Resize(target_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ í›„ GPUë¡œ ì´ë™
    return image

# ì¶”ë¡  í•¨ìˆ˜ (Inference)
def predict_pose(image_path):
    image = preprocess_image(image_path)
    
    with torch.no_grad():
        output = model(image)  # (1, 17, 2) í˜•íƒœì˜ (x, y) ì¢Œí‘œ ì˜ˆì¸¡

    keypoints = output.cpu().numpy()[0]  # NumPy ë°°ì—´ ë³€í™˜
    return keypoints

# ì‹œê°í™” í•¨ìˆ˜ (Visualization)
def visualize_keypoints(image_path, keypoints):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR â†’ RGB ë³€í™˜
    h, w, _ = image.shape

    # 0~1 ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
    keypoints[:, 0] *= w
    keypoints[:, 1] *= h

    # í‚¤í¬ì¸íŠ¸ ì°ê¸°
    for (x, y) in keypoints:
        cv2.circle(image, (int(x), int(y)), 5, (0, 255, 0), -1)  # ğŸŸ¢ ì´ˆë¡ìƒ‰ ì 

    # ê´€ì ˆ ì—°ê²°ì„  ì¶”ê°€
    for (i, j) in COCO_SKELETON:
        pt1 = tuple(keypoints[i].astype(int))
        pt2 = tuple(keypoints[j].astype(int))
        cv2.line(image, pt1, pt2, (255, 0, 0), 2)  # ğŸ”µ íŒŒë€ìƒ‰ ì„ ìœ¼ë¡œ ì—°ê²°

    # ê²°ê³¼ ì¶œë ¥
    plt.figure(figsize=(8, 6))
    plt.imshow(image)
    plt.axis("off")
    plt.title("Pose Estimation with Skeleton")
    plt.show()

# ì‹¤í–‰
if __name__ == "__main__":
    image_path = "C:/Users/dev/Documents/GitHub/sideProject/Human Pose Estimation/data/val2017/15.jpg"
    keypoints = predict_pose(image_path)

    print("âœ… Inference completed! Predicted Keypoints:\n", keypoints)
    visualize_keypoints(image_path, keypoints)
